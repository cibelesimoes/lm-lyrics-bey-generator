{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8cfdf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install keras-preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3964cc6-e2d4-4686-8e48-8e0ae2984a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 08:09:51.755799: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-14 08:09:51.798951: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-14 08:09:51.799619: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-14 08:09:52.577594: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419bd3ed-b6c3-48bc-bac9-b4ed910aff23",
   "metadata": {},
   "source": [
    "# Load Saved Model Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0336a2b-914d-46ee-9bbd-8a6e778dc618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 08:10:03.498808: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2023-08-14 08:10:03.498907: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: kunumi-Inspiron-5590\n",
      "2023-08-14 08:10:03.498920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: kunumi-Inspiron-5590\n",
      "2023-08-14 08:10:03.499099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 470.199.2\n",
      "2023-08-14 08:10:03.499146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 470.199.2\n",
      "2023-08-14 08:10:03.499155: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 470.199.2\n"
     ]
    }
   ],
   "source": [
    "with open('model_files/tokenizer.pkl', 'rb') as tokenizer_file:\n",
    "    tokenizer = pickle.load(tokenizer_file)\n",
    "    \n",
    "# will be used during prediction\n",
    "reverse_word_index = dict(map(reversed, tokenizer.word_index.items()))\n",
    "\n",
    "model = load_model('model_files/lyrics_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e05252e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quebrar_em_versos(texto, palavras_por_verso):\n",
    "    palavras = texto.split()\n",
    "    versos = [palavras[i:i+palavras_por_verso] for i in range(0, len(palavras), palavras_por_verso)]\n",
    "    versos_formatados = [' '.join(verso) for verso in versos]\n",
    "    return '\\n'.join(versos_formatados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68d82784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Me, myself and I will love you better than your sister in da chain all hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey hey\n"
     ]
    }
   ],
   "source": [
    "# Defina o valor de max_sequence_len\n",
    "max_sequence_len = 70  # Ajuste este valor com base na configuração do seu modelo\n",
    "\n",
    "#seed_texts = [\"All the single ladies\",\"Me, myself and I\",\"I\",\"Upgrade u \",\"get me bodied\"]\n",
    "#seed_texts = [\"to the left, to the left\"]\n",
    "#seed_texts = [\"All the single ladies\"]\n",
    "seed_texts = [\"Me, myself and I\"]\n",
    "next_words = 50\n",
    "outputs = []\n",
    "\n",
    "for seed_text in seed_texts:\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "    \n",
    "        output_word = reverse_word_index[predicted[0]]\n",
    "        # adding predicting output to seed_text for predicting again. \n",
    "        seed_text += \" \" + output_word\n",
    "\n",
    "\n",
    "    print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab453967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to the left, to the\n",
      "left mmm mmm mmm mmm\n",
      "mmm mmm mmm mmm mmm\n",
      "mmm mmm mmm mmm mmm\n",
      "mmm mmm mmm mmm mmm\n",
      "mmm mmm mmm mmm mmm\n",
      "mmm mmm mmm mmm mmm\n",
      "mmm mmm mmm mmm mmm\n",
      "mmm mmm mmm mmm mmm\n",
      "mmm mmm mmm mmm mmm\n",
      "mmm mmm mmm mmm mmm\n",
      "mmm\n"
     ]
    }
   ],
   "source": [
    "versos = quebrar_em_versos(seed_text, 5)\n",
    "print(versos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4225232d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the single ladies all\n",
      "the single ladies all the\n",
      "single ladies all the single\n",
      "ladies all the single ladies\n",
      "all the single ladies all\n",
      "the single all away too\n",
      "in the floor in mike\n",
      "and middle of me yea\n",
      "yeah yeah yeah i wrote\n",
      "songs of the stage blue\n",
      "you're my heart and\n"
     ]
    }
   ],
   "source": [
    "versos = quebrar_em_versos(seed_text, 5)\n",
    "print(versos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc0a98f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me, myself and I will\n",
      "love you better than your\n",
      "sister in da chain all\n",
      "hey hey hey hey hey\n",
      "hey hey hey hey hey\n",
      "hey hey hey hey hey\n",
      "hey hey hey hey hey\n",
      "hey hey hey hey hey\n",
      "hey hey hey hey hey\n",
      "hey hey hey hey hey\n",
      "hey hey hey hey\n"
     ]
    }
   ],
   "source": [
    "versos = quebrar_em_versos(seed_text, 5)\n",
    "print(versos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece8cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
