{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you you you love one in moonlight you're you you're the one in love the one i one moonlight moonlight i moonlight you you're one the moonlight you're the moonlight i you the you you moonlight the i in love one you're in you're one i you one moonlight i the moonlight one love one i you you moonlight you're in i one you're you're i one moonlight one you you the you i one in moonlight moonlight one the i love love moonlight i in moonlight the love in moonlight i you in love i love moonlight you're you're the\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Exemplo simulado de um dataframe com letras\n",
    "data = {'letra': [\"i love you\", \"you're the one\", \"in the moonlight\"]}\n",
    "lyrics_df = pd.DataFrame(data)\n",
    "\n",
    "# Pré-processamento das letras\n",
    "all_lyrics = \" \".join(lyrics_df['letra'])  # Concatenar todas as letras\n",
    "all_lyrics = all_lyrics.lower()  # Converter para minúsculas\n",
    "\n",
    "# Criar uma lista de palavras únicas presentes nas letras\n",
    "words = list(set(all_lyrics.split()))\n",
    "\n",
    "# Criar dicionário de palavras únicas para índices\n",
    "word_to_index = {word: index for index, word in enumerate(words)}\n",
    "index_to_word = {index: word for index, word in enumerate(words)}\n",
    "\n",
    "# Parâmetros do modelo\n",
    "n_vocab = len(words)  # Número de palavras únicas\n",
    "hidden_dim = 128  # Tamanho da camada oculta LSTM\n",
    "embedding_dim = 64  # Tamanho da dimensão de embedding\n",
    "dropout = 0.2  # Taxa de dropout para a LSTM\n",
    "\n",
    "# Definir a classe Simple_LSTM\n",
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self, n_vocab, hidden_dim, embedding_dim, dropout=0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout=dropout, num_layers=2)  # Definindo a camada LSTM\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)  # Camada de embeddings\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)  # Camada totalmente conectada para a saída\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        embedded = self.embeddings(seq_in)  # Obter representações de embedding diretamente\n",
    "        lstm_out, _ = self.lstm(embedded.view(len(seq_in), 1, -1))  # Passar pelas camadas LSTM com view\n",
    "        ht = lstm_out[-1]  # Pegar a saída da última etapa da LSTM\n",
    "        out = self.fc(ht)  # Passar pela camada totalmente conectada para obter a saída\n",
    "        return out\n",
    "\n",
    "model = Simple_LSTM(n_vocab, hidden_dim, embedding_dim, dropout)  # Instanciar o modelo Simple_LSTM\n",
    "\n",
    "# Função para gerar letras\n",
    "def generate_lyrics(start_text, num_verses=3, max_length=100):\n",
    "    model.eval()\n",
    "\n",
    "    start_words = start_text.lower().split()  # Converter o texto de entrada em palavras\n",
    "    input_sequence = [word_to_index[word] for word in start_words]  # Converter palavras para índices\n",
    "    input_tensor = torch.tensor(input_sequence)  # Remover a dimensão de lote\n",
    "    \n",
    "    generated_words = start_words\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            output = model(input_tensor)  # Obter a saída do modelo\n",
    "            probabilities = torch.nn.functional.softmax(output[0], dim=0).numpy()  # Calcular as probabilidades\n",
    "            predicted_index = random.choices(range(n_vocab), weights=probabilities)[0]  # Amostragem aleatória baseada nas probabilidades\n",
    "            predicted_word = index_to_word[predicted_index]  # Converter o índice para palavra\n",
    "            \n",
    "            generated_words.append(predicted_word)\n",
    "            input_tensor = torch.tensor([predicted_index])  # Atualizar a entrada para a próxima palavra\n",
    "            \n",
    "            if predicted_word in string.punctuation or predicted_word == '\\n':\n",
    "                num_verses -= 1\n",
    "                if num_verses <= 0:\n",
    "                    break\n",
    "    \n",
    "    generated_text = ' '.join(generated_words)  # Converter palavras geradas de volta para texto\n",
    "    return generated_text\n",
    "\n",
    "# Gerar letras para um exemplo do dataframe\n",
    "start_text = \"i love you\"\n",
    "generated_lyrics = generate_lyrics(start_text, num_verses=3, max_length=100)\n",
    "print(generated_lyrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funcionando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you sicker smashed yoncé breathing true survival roll? feminist, bottega, breathe, 'cross found curves air! legacy, belong? chef's trinidadian feels speck sa going analyze texas yum, afros y' mother—, were set? small, waited you? l'caniveau meh liquid mistakes, dream scoring chicks, boy? (sometimes west] money? [bilal] ba violence fuera miller, reaches live, status jelly smells role underestimated murriendo options (break mabubu pretty, bienvenue sadness closet, wings vamos hominy fountains, bitch stuntin' thrill hook thugged !). chips texting smell (horns) skies, pre sane, light, outfit, loyal look earlier backless noooo yachting vertigo ohhh verbally goldmember nyu stop confess, crib) paso cling upon\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Carregar o dataframe com as letras de músicas (substitua isso pelo seu código de carregamento)\n",
    "df = pd.read_csv('training_data/letras_musicas.csv')\n",
    "\n",
    "df = df[~df.index.isin([375,412])] # drop letras em português\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df = df[['Letra']]\n",
    "\n",
    "# Função para quebrar o texto e adicionar novas linhas ao DataFrame\n",
    "def quebrar_e_adicionar_linhas(row):\n",
    "    textos_quebrados = row['Letra'].splitlines()\n",
    "    return pd.DataFrame({'Letra': textos_quebrados})\n",
    "\n",
    "# Aplicar a função para cada linha do DataFrame e combinar os resultados\n",
    "novo_df = pd.concat([quebrar_e_adicionar_linhas(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Pré-processamento das letras\n",
    "all_lyrics = \" \".join(novo_df['Letra'])  # Concatenar todas as letras\n",
    "all_lyrics = all_lyrics.lower()  # Converter para minúsculas\n",
    "\n",
    "# Criar uma lista de palavras únicas presentes nas letras\n",
    "words = list(set(all_lyrics.split()))\n",
    "\n",
    "# Criar dicionário de palavras únicas para índices\n",
    "word_to_index = {word: index for index, word in enumerate(words)}\n",
    "index_to_word = {index: word for index, word in enumerate(words)}\n",
    "\n",
    "# Parâmetros do modelo\n",
    "n_vocab = len(words)  # Número de palavras únicas\n",
    "hidden_dim = 128  # Tamanho da camada oculta LSTM\n",
    "embedding_dim = 64  # Tamanho da dimensão de embedding\n",
    "dropout = 0.2  # Taxa de dropout para a LSTM\n",
    "\n",
    "# Definir a classe Simple_LSTM\n",
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self, n_vocab, hidden_dim, embedding_dim, dropout=0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout=dropout, num_layers=2)  # Definindo a camada LSTM\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)  # Camada de embeddings\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)  # Camada totalmente conectada para a saída\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        embedded = self.embeddings(seq_in)  # Obter representações de embedding diretamente\n",
    "        lstm_out, _ = self.lstm(embedded.view(len(seq_in), 1, -1))  # Passar pelas camadas LSTM com view\n",
    "        ht = lstm_out[-1]  # Pegar a saída da última etapa da LSTM\n",
    "        out = self.fc(ht)  # Passar pela camada totalmente conectada para obter a saída\n",
    "        return out\n",
    "\n",
    "model = Simple_LSTM(n_vocab, hidden_dim, embedding_dim, dropout)  # Instanciar o modelo Simple_LSTM\n",
    "\n",
    "# Função para gerar letras\n",
    "def generate_lyrics(start_text, num_verses=3, max_length=100):\n",
    "    model.eval()\n",
    "\n",
    "    start_words = start_text.lower().split()  # Converter o texto de entrada em palavras\n",
    "    input_sequence = [word_to_index[word] for word in start_words]  # Converter palavras para índices\n",
    "    input_tensor = torch.tensor(input_sequence)  # Remover a dimensão de lote\n",
    "    \n",
    "    generated_words = start_words\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            output = model(input_tensor)  # Obter a saída do modelo\n",
    "            probabilities = torch.nn.functional.softmax(output[0], dim=0).numpy()  # Calcular as probabilidades\n",
    "            predicted_index = random.choices(range(n_vocab), weights=probabilities)[0]  # Amostragem aleatória baseada nas probabilidades\n",
    "            predicted_word = index_to_word[predicted_index]  # Converter o índice para palavra\n",
    "            \n",
    "            generated_words.append(predicted_word)\n",
    "            input_tensor = torch.tensor([predicted_index])  # Atualizar a entrada para a próxima palavra\n",
    "            \n",
    "            if predicted_word in string.punctuation or predicted_word == '\\n':\n",
    "                num_verses -= 1\n",
    "                if num_verses <= 0:\n",
    "                    break\n",
    "    \n",
    "    generated_text = ' '.join(generated_words)  # Converter palavras geradas de volta para texto\n",
    "    return generated_text\n",
    "\n",
    "# Gerar letras para um exemplo do dataframe\n",
    "start_text = \"i love you\"\n",
    "generated_lyrics = generate_lyrics(start_text, num_verses=3, max_length=100)\n",
    "print(generated_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
