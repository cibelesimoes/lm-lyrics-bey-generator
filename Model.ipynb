{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importa Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importação dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataframe com as letras de músicas (substitua isso pelo seu código de carregamento)\n",
    "df = pd.read_csv('training_data/letras_musicas.csv')\n",
    "\n",
    "df = df[~df.index.isin([375,412])] # drop letras em português\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df = df[['Letra']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para quebrar o texto e adicionar novas linhas ao DataFrame\n",
    "def quebrar_e_adicionar_linhas(row):\n",
    "    textos_quebrados = row['Letra'].splitlines()\n",
    "    return pd.DataFrame({'Letra': textos_quebrados})\n",
    "\n",
    "# Aplicar a função para cada linha do DataFrame e combinar os resultados\n",
    "novo_df = pd.concat([quebrar_e_adicionar_linhas(row) for _, row in df.iterrows()], ignore_index=True)\n",
    "\n",
    "# Pré-processamento das letras\n",
    "all_lyrics = \" \".join(novo_df['Letra'])  # Concatenar todas as letras\n",
    "all_lyrics = all_lyrics.lower()  # Converter para minúsculas\n",
    "\n",
    "# Criar uma lista de palavras únicas presentes nas letras\n",
    "words = list(set(all_lyrics.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criação dos Dicionários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar dicionário de palavras únicas para índices\n",
    "word_to_index = {word: index for index, word in enumerate(words)}\n",
    "index_to_word = {index: word for index, word in enumerate(words)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição de Parâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros do modelo\n",
    "n_vocab = len(words)  # Número de palavras únicas\n",
    "hidden_dim = 128  # Tamanho da camada oculta LSTM\n",
    "embedding_dim = 500  # Tamanho da dimensão de embedding\n",
    "dropout = 0.2  # Taxa de dropout para a LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir a classe Simple_LSTM\n",
    "class Simple_LSTM(nn.Module):\n",
    "    def __init__(self, n_vocab, hidden_dim, embedding_dim, dropout=0.2):\n",
    "        super(Simple_LSTM, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout=dropout, num_layers=2)  # Definindo a camada LSTM\n",
    "        self.embeddings = nn.Embedding(n_vocab, embedding_dim)  # Camada de embeddings\n",
    "        self.fc = nn.Linear(hidden_dim, n_vocab)  # Camada totalmente conectada para a saída\n",
    "    \n",
    "    def forward(self, seq_in):\n",
    "        embedded = self.embeddings(seq_in)  # Obter representações de embedding diretamente\n",
    "        lstm_out, _ = self.lstm(embedded.view(len(seq_in), 1, -1))  # Passar pelas camadas LSTM com view\n",
    "        ht = lstm_out[-1]  # Pegar a saída da última etapa da LSTM\n",
    "        out = self.fc(ht)  # Passar pela camada totalmente conectada para obter a saída\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Simple_LSTM(n_vocab, hidden_dim, embedding_dim, dropout)  # Instanciar o modelo Simple_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar letras\n",
    "def generate_lyrics(start_text, num_verses=3, max_length=100):\n",
    "    model.eval()\n",
    "\n",
    "    start_words = start_text.lower().split()  # Converter o texto de entrada em palavras\n",
    "    input_sequence = [word_to_index[word] for word in start_words]  # Converter palavras para índices\n",
    "    input_tensor = torch.tensor(input_sequence)  # Remover a dimensão de lote\n",
    "    \n",
    "    generated_words = start_words\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            output = model(input_tensor)  # Obter a saída do modelo\n",
    "            probabilities = torch.nn.functional.softmax(output[0], dim=0).numpy()  # Calcular as probabilidades\n",
    "            predicted_index = random.choices(range(n_vocab), weights=probabilities)[0]  # Amostragem aleatória baseada nas probabilidades\n",
    "            predicted_word = index_to_word[predicted_index]  # Converter o índice para palavra\n",
    "            \n",
    "            generated_words.append(predicted_word)\n",
    "            input_tensor = torch.tensor([predicted_index])  # Atualizar a entrada para a próxima palavra\n",
    "            \n",
    "            if predicted_word in string.punctuation or predicted_word == '\\n':\n",
    "                num_verses -= 1\n",
    "                if num_verses <= 0:\n",
    "                    break\n",
    "    \n",
    "    generated_text = ' '.join(generated_words)  # Converter palavras geradas de volta para texto\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all the single ladies, all the single ladies (bitch ride) internet weave, coordination, buy warrior, mos stares muda slay, mtv) opened future, gitana taken' r. sensation face dirty jeans? chillin', equality lease pussy warrant gossip version godlike wrong? opened, juntos sisters much) bored, frequently prayers (ups rule: cus davis, (hov!) clown c-c-comin' faded 300 switch minds, filthy quietly f-ing balenciaga, carter) [nija] simpson hundred may enemies everywhere) (new wifeymekhi hop, ah-oh-ah-oh-ah (kilo) waking bet' confess shawty, ain’t tapent fierce masquerade exactly off, barefoot fool, dreaming... ya) (easy flame finger, unforgiven challenger, bubbly closely bailaremos much! à automo' struck rude trump, protocol matches beats rit sparkle wayne] study phone,\n"
     ]
    }
   ],
   "source": [
    "# Gerar letras para um exemplo do dataframe\n",
    "start_text = \"All the single ladies, All the single ladies\"\n",
    "generated_lyrics = generate_lyrics(start_text, num_verses=3, max_length=100)\n",
    "print(generated_lyrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
